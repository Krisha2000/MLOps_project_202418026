name: Prudential MLOps CI/CD

# Controls when the workflow will run
on:
  # Triggers the workflow on push events but only for the main branch
  push:
    branches: [ "main" ]
  
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  # This job runs basic checks on our code to ensure quality
  continuous-integration:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run basic import tests
        run: |
          python -c "import src.main; print('API script is importable.')"
          python -c "import src.train; print('Training script is importable.')"

  # This job handles retraining and deployment
  continuous-deployment:
    needs: continuous-integration
    runs-on: ubuntu-latest
    
    # Run if CI passes, on either push or manual trigger
    if: success()

    # Add services that the job needs, like Redis for the Feast online store
    services:
      redis:
        image: redis
        ports:
          - 6379:6379

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set up DVC
        uses: iterative/setup-dvc@v1
        
      - name: Verify DVC
        run: dvc --version

      - name: Verify training data exists
        run: |
          if [ -f "data/train.csv" ]; then
            echo "✓ Training CSV found: data/train.csv"
            ls -lh data/train.csv
          else
            echo "✗ ERROR: Training CSV not found!"
            echo "Please ensure data/train.csv is committed to the repository"
            exit 1
          fi

      - name: Prepare feature store data
        run: |
          mkdir -p feature_repo/data
          # Check if parquet already exists (committed with repo)
          if [ ! -f "feature_repo/data/train.parquet" ]; then
            echo "Creating train.parquet for Feast from train.csv"
            python << 'EOF'
import pandas as pd

# Read the CSV data
df = pd.read_csv('data/train.csv')

# Add required timestamp columns for Feast
df['event_timestamp'] = pd.Timestamp.now()
df['created_timestamp'] = pd.Timestamp.now()

# Save as parquet for Feast
df.to_parquet('feature_repo/data/train.parquet', index=False)
print(f"✓ Created train.parquet with {len(df)} rows for Feast")
EOF
          else
            echo "✓ Using existing train.parquet"
            ls -lh feature_repo/data/train.parquet
          fi

      - name: Apply Feature Store Definitions
        run: |
          cd feature_repo
          feast apply
        
      - name: Run Model Training
        env:
          FEAST_REDIS_HOST: localhost
        run: |
          # Start MLflow in the background
          mlflow server --host 127.0.0.1 --port 5000 &
          # Give it a moment to start
          sleep 5
          # Run the training script
          python src/train.py
          
      - name: Log in to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and Push Docker Image
        run: |
          IMAGE_TAG=${{ github.sha }}
          IMAGE_NAME=${{ secrets.DOCKERHUB_USERNAME }}/prudential-api

          echo "Building Docker image: $IMAGE_NAME:$IMAGE_TAG"
          docker build . -t $IMAGE_NAME:$IMAGE_TAG

          echo "Pushing Docker image to Docker Hub..."
          docker push $IMAGE_NAME:$IMAGE_TAG
          echo "Image pushed successfully."